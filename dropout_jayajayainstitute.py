# -*- coding: utf-8 -*-
"""Dropout_JayaJayaInstitute.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_1OEp8IC_Jc_7xtKANmCPrzotGjyq4ss

# Proyek Akhir: Menyelesaikan Permasalahan Perusahaan Edutech

- Nama: Muhammad Rizki
- Email: mrizki135790@gmail.com
- Id Dicoding: rizki_muhammad

## Persiapan

### Menyiapkan library yang dibutuhkan
"""

# =====================================
# 1. PERSIAPAN - Menyiapkan Library
# =====================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# Machine Learning Libraries
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, roc_curve
from sklearn.tree import DecisionTreeClassifier

# Untuk visualisasi yang lebih baik
plt.style.use('default')
sns.set_palette("husl")

print("‚úÖ Library berhasil diimport!")

"""### Menyiapkan data yang akan diguankan

## Data Understanding
"""

# =====================================
# 2. DATA UNDERSTANDING
# =====================================

# Load dataset
url = "https://raw.githubusercontent.com/dicodingacademy/dicoding_dataset/main/students_performance/data.csv"
df = pd.read_csv(url, delimiter=';')

print("üìä INFORMASI DATASET")
print("="*50)
print(f"Ukuran dataset: {df.shape}")
print(f"Jumlah baris: {df.shape[0]}")
print(f"Jumlah kolom: {df.shape[1]}")

print("\nüìã INFO DATASET:")
print(df.info())

print("\nüìà STATISTIK DESKRIPTIF:")
print(df.describe())

print("\nüéØ TARGET VARIABLE (Status):")
print(df['Status'].value_counts())

print("\nüìä PROPORSI TARGET:")
status_prop = df['Status'].value_counts(normalize=True) * 100
print(f"Graduate: {status_prop['Graduate']:.2f}%")
print(f"Dropout: {status_prop['Dropout']:.2f}%")
if 'Enrolled' in status_prop:
    print(f"Enrolled: {status_prop['Enrolled']:.2f}%")

# Cek missing values
print("\n‚ùì MISSING VALUES:")
missing_values = df.isnull().sum()
print(missing_values[missing_values > 0])

if missing_values.sum() == 0:
    print("‚úÖ Tidak ada missing values!")

# Tampilkan sample data
print("\nüìù SAMPLE DATA (5 baris pertama):")
print(df.head())

# =====================================
# 3. EXPLORATORY DATA ANALYSIS (EDA)
# =====================================

# Visualisasi distribusi target variable
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
df['Status'].value_counts().plot(kind='bar', color=['skyblue', 'orange', 'lightgreen'])
plt.title('Distribusi Status Mahasiswa')
plt.ylabel('Jumlah')
plt.xticks(rotation=45)

plt.subplot(1, 3, 2)
df['Status'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90)
plt.title('Proporsi Status Mahasiswa')

# Analisis berdasarkan gender
plt.subplot(1, 3, 3)
pd.crosstab(df['Gender'], df['Status']).plot(kind='bar', stacked=True)
plt.title('Status berdasarkan Gender')
plt.ylabel('Jumlah')
plt.xticks(rotation=0)

plt.tight_layout()
plt.show()

# Analisis korelasi untuk variabel numerik
numeric_cols = df.select_dtypes(include=[np.number]).columns
print(f"\nüî¢ KOLOM NUMERIK: {len(numeric_cols)} kolom")
print(list(numeric_cols))

# Heatmap korelasi
plt.figure(figsize=(12, 10))
correlation_matrix = df[numeric_cols].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')
plt.title('Korelasi Antar Variabel Numerik')
plt.tight_layout()
plt.show()

# Analisis faktor-faktor penting
important_factors = ['Age_at_enrollment', 'Admission_grade', 'Curricular_units_1st_sem_grade',
                    'Curricular_units_2nd_sem_grade', 'Tuition_fees_up_to_date', 'Scholarship_holder']

fig, axes = plt.subplots(2, 3, figsize=(18, 12))
axes = axes.ravel()

for i, col in enumerate(important_factors):
    if col in df.columns:
        if df[col].dtype in ['int64', 'float64']:
            df.boxplot(column=col, by='Status', ax=axes[i])
            axes[i].set_title(f'{col} berdasarkan Status')
        else:
            pd.crosstab(df[col], df['Status']).plot(kind='bar', ax=axes[i])
            axes[i].set_title(f'{col} berdasarkan Status')

plt.tight_layout()
plt.show()

"""## Data Preparation / Preprocessing"""

# =====================================
# 4. DATA PREPARATION / PREPROCESSING
# =====================================

print("\nüîß DATA PREPROCESSING")
print("="*50)

# Buat copy dataset untuk preprocessing
df_processed = df.copy()

# Encode categorical variables
label_encoders = {}
categorical_cols = df_processed.select_dtypes(include=['object']).columns

print(f"üìã Kolom kategorikal yang akan di-encode: {len(categorical_cols)} kolom")

for col in categorical_cols:
    if col != 'Status':  # Jangan encode target variable dulu
        le = LabelEncoder()
        df_processed[col] = le.fit_transform(df_processed[col])
        label_encoders[col] = le

# Encode target variable
target_encoder = LabelEncoder()
df_processed['Status'] = target_encoder.fit_transform(df_processed['Status'])

print(f"‚úÖ Target encoding: {dict(zip(target_encoder.classes_, target_encoder.transform(target_encoder.classes_)))}")

# Pisahkan features dan target
X = df_processed.drop('Status', axis=1)
y = df_processed['Status']

print(f"\nüìä Ukuran data setelah preprocessing:")
print(f"Features (X): {X.shape}")
print(f"Target (y): {y.shape}")

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print(f"\n‚úÇÔ∏è Data splitting:")
print(f"Training set: {X_train.shape[0]} samples")
print(f"Test set: {X_test.shape[0]} samples")

# Scaling features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("‚úÖ Feature scaling selesai!")

"""## Modeling"""

# =====================================
# 5. MODELING
# =====================================

print("\nü§ñ MACHINE LEARNING MODELING")
print("="*50)

# Inisialisasi models
models = {
    'Logistic Regression': LogisticRegression(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'SVM': SVC(random_state=42, probability=True)
}

# Training dan evaluasi models
model_results = {}

for name, model in models.items():
    print(f"\nüîÑ Training {name}...")

    # Training
    if name == 'SVM':
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        y_pred_proba = model.predict_proba(X_test)[:, 1]

    # Evaluasi
    accuracy = accuracy_score(y_test, y_pred)

    # Cross validation
    if name == 'SVM':
        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)
    else:
        cv_scores = cross_val_score(model, X_train, y_train, cv=5)

    model_results[name] = {
        'model': model,
        'accuracy': accuracy,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std(),
        'y_pred': y_pred,
        'y_pred_proba': y_pred_proba
    }

    print(f"‚úÖ {name} - Accuracy: {accuracy:.4f}, CV: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})")

"""## Evaluation"""

# =====================================
# 6. EVALUATION
# =====================================

print("\nüìä MODEL EVALUATION")
print("="*50)

# Comparison table
results_df = pd.DataFrame({
    'Model': list(model_results.keys()),
    'Accuracy': [results['accuracy'] for results in model_results.values()],
    'CV Mean': [results['cv_mean'] for results in model_results.values()],
    'CV Std': [results['cv_std'] for results in model_results.values()]
})

print(results_df.round(4))

# Find best model (berdasarkan Accuracy)
best_model_name = results_df.loc[results_df['Accuracy'].idxmax(), 'Model']
best_model = model_results[best_model_name]['model']

print(f"\nüèÜ BEST MODEL: {best_model_name}")
print(f"Accuracy: {model_results[best_model_name]['accuracy']:.4f}")

# Detailed evaluation for best model
print(f"\nüìã CLASSIFICATION REPORT - {best_model_name}:")
print(classification_report(
    y_test,
    model_results[best_model_name]['y_pred'],
    target_names=target_encoder.classes_
))

# Confusion Matrix
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
cm = confusion_matrix(y_test, model_results[best_model_name]['y_pred'])
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=target_encoder.classes_,
            yticklabels=target_encoder.classes_)
plt.title(f'Confusion Matrix - {best_model_name}')
plt.ylabel('Actual')
plt.xlabel('Predicted')

# Model Comparison (Accuracy)
plt.subplot(1, 2, 2)
model_names = list(model_results.keys())
accuracies = [model_results[name]['accuracy'] for name in model_names]

plt.bar(model_names, accuracies, alpha=0.8)
plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.title('Model Performance Comparison')
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

# Feature Importance (untuk tree-based models)
if hasattr(best_model, 'feature_importances_'):
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': best_model.feature_importances_
    }).sort_values('importance', ascending=False)

    print(f"\nüéØ TOP 10 FEATURE IMPORTANCE - {best_model_name}:")
    print(feature_importance.head(10))

    plt.figure(figsize=(12, 8))
    plt.subplot(2, 1, 1)
    sns.barplot(data=feature_importance.head(10), x='importance', y='feature')
    plt.title(f'Top 10 Feature Importance - {best_model_name}')

    # Feature importance distribution
    plt.subplot(2, 1, 2)
    plt.hist(feature_importance['importance'], bins=20, alpha=0.7)
    plt.xlabel('Importance Score')
    plt.ylabel('Number of Features')
    plt.title('Distribution of Feature Importance')

    plt.tight_layout()
    plt.show()

# =====================================
# 7. BUSINESS INSIGHTS & RECOMMENDATIONS
# =====================================

print("\nüíº BUSINESS INSIGHTS & RECOMMENDATIONS")
print("="*60)

print("üéØ KEY FINDINGS:")
print("1. Model terbaik:", best_model_name)
print(f"2. Akurasi prediksi: {model_results[best_model_name]['accuracy']:.1%}")

# Analisis distribusi prediksi
dropout_prob = model_results[best_model_name]['y_pred_proba']
high_risk_threshold = 0.7
high_risk_students = np.sum(dropout_prob > high_risk_threshold)

print(f"\nüìä RISK ANALYSIS:")
print(f"‚Ä¢ Mahasiswa berisiko tinggi dropout (>70%): {high_risk_students} dari {len(dropout_prob)} ({high_risk_students/len(dropout_prob)*100:.1f}%)")
print(f"‚Ä¢ Mahasiswa berisiko sedang (30-70%): {np.sum((dropout_prob >= 0.3) & (dropout_prob <= 0.7))}")
print(f"‚Ä¢ Mahasiswa berisiko rendah (<30%): {np.sum(dropout_prob < 0.3)}")

print(f"\nüí° REKOMENDASI BISNIS:")
print("1. üéØ EARLY WARNING SYSTEM:")
print("   - Implementasikan sistem monitoring otomatis")
print("   - Identifikasi mahasiswa berisiko tinggi setiap semester")
print("   - Berikan intervensi dini untuk mahasiswa dengan probabilitas dropout >70%")

print("\n2. üìö PROGRAM INTERVENSI:")
print("   - Bimbingan akademik intensif untuk mahasiswa berisiko tinggi")
print("   - Program mentoring dan konseling")
print("   - Fleksibilitas pembayaran untuk masalah finansial")

print("\n3. üìà MONITORING & EVALUATION:")
print("   - Update model secara berkala dengan data terbaru")
print("   - Track efektivitas program intervensi")
print("   - Analisis faktor-faktor baru yang mempengaruhi dropout")

print(f"\n4. üéØ FOKUS AREA UTAMA:")
if hasattr(best_model, 'feature_importances_'):
    top_3_features = feature_importance.head(3)['feature'].tolist()
    print(f"   - Perhatikan khusus pada: {', '.join(top_3_features)}")

print("\n‚úÖ PROYEK SELESAI!")
print("Dataset berhasil dianalisis dan model prediksi dropout telah dibuat.")
print("Model dapat digunakan untuk identifikasi dini mahasiswa berisiko dropout.")

# Save hasil untuk deployment
print(f"\nüíæ Untuk deployment, simpan:")
print("- Model terbaik: best_model")
print("- Scaler: scaler")
print("- Label encoders: label_encoders")
print("- Target encoder: target_encoder")

